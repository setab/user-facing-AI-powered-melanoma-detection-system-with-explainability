# Abstract

Early detection remains critical in melanoma diagnosis, where treatment success strongly correlates with disease stage at identification. While dermoscopic imaging has become standard practice in clinical settings, interpreting these images requires specialized training and experience that many primary care providers lack. This work addresses the need for accessible, reliable diagnostic support by developing an integrated deep learning system that combines accurate classification with clinically-relevant explainability features.

I implemented and compared four convolutional neural network architectures—ResNet-50, EfficientNet-B3, DenseNet-121, and Vision Transformer (ViT-B/16)—on the HAM10000 dataset containing 10,013 dermoscopic images across seven diagnostic categories. Each model was trained for 20 epochs using identical preprocessing pipelines and training procedures to ensure fair comparison. The system incorporates temperature scaling for probability calibration and establishes operating thresholds optimized for 95% specificity, reflecting real-world clinical requirements where false positives carry significant costs.

EfficientNet-B3 emerged as the best-performing architecture, achieving 89.22% overall accuracy and 95.34% AUC for melanoma detection. At the clinically-relevant operating point, the model demonstrated 80.72% sensitivity for melanoma identification while maintaining 95% specificity, with an inference time of 10.06 milliseconds suitable for real-time applications. Temperature scaling improved calibration across all models, with expected calibration errors below 3% indicating reliable probability estimates.

Beyond classification accuracy, the system provides visual explanations through Gradient-weighted Class Activation Mapping (Grad-CAM), highlighting regions of dermoscopic images that most influence model decisions. These attention maps correlate with established clinical criteria from the ABCDE melanoma detection protocol, offering diagnostically meaningful insights rather than opaque predictions. An interactive web interface built with Gradio enables healthcare providers to upload dermoscopic images, receive calibrated probability estimates, view attention heatmaps, and access AI-generated explanations that contextualize predictions with relevant medical knowledge.

The key contributions of this work include: (1) a systematic comparison of modern deep learning architectures on melanoma classification under identical training conditions, (2) integration of temperature calibration with clinically-motivated operating thresholds, (3) implementation of explainable AI techniques that align with dermatological criteria, and (4) deployment of an accessible web interface that packages these capabilities for practical clinical use. Results demonstrate that deep learning can achieve dermatologist-level performance on melanoma detection while providing the transparency necessary for clinical adoption. The complete system—including trained models, calibration parameters, and deployment code—is documented for reproducibility and potential adaptation to other medical imaging domains.
