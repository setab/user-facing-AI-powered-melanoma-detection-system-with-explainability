# References

## Primary Sources

1. **Esteva, A., Kuprel, B., Novoa, R. A., Ko, J., Swetter, S. M., Blau, H. M., & Thrun, S.** (2017). Dermatologist-level classification of skin cancer with deep neural networks. *Nature*, 542(7639), 115-118. DOI: 10.1038/nature21056

2. **Tschandl, P., Rosendahl, C., & Kittler, H.** (2018). The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. *Scientific Data*, 5, 180161. DOI: 10.1038/sdata.2018.161

3. **Haenssle, H. A., Fink, C., Schneiderbauer, R., Toberer, F., Buhl, T., Blum, A., ... & Enk, A.** (2018). Man against machine: diagnostic performance of a deep learning convolutional neural network for dermoscopic melanoma recognition in comparison to 58 dermatologists. *Annals of Oncology*, 29(8), 1836-1842. DOI: 10.1093/annonc/mdy166

4. **Guo, C., Pleiss, G., Sun, Y., & Weinberger, K. Q.** (2017). On calibration of modern neural networks. *Proceedings of the 34th International Conference on Machine Learning* (ICML), 1321-1330.

5. **Selvaraju, R. R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., & Batra, D.** (2017). Grad-CAM: Visual explanations from deep networks via gradient-based localization. *Proceedings of the IEEE International Conference on Computer Vision* (ICCV), 618-626. DOI: 10.1109/ICCV.2017.74

## Deep Learning Architectures

6. **He, K., Zhang, X., Ren, S., & Sun, J.** (2016). Deep residual learning for image recognition. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition* (CVPR), 770-778. DOI: 10.1109/CVPR.2016.90

7. **Tan, M., & Le, Q. V.** (2019). EfficientNet: Rethinking model scaling for convolutional neural networks. *Proceedings of the 36th International Conference on Machine Learning* (ICML), 6105-6114.

8. **Huang, G., Liu, Z., Van Der Maaten, L., & Weinberger, K. Q.** (2017). Densely connected convolutional networks. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition* (CVPR), 4700-4708. DOI: 10.1109/CVPR.2017.243

9. **Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N.** (2021). An image is worth 16x16 words: Transformers for image recognition at scale. *International Conference on Learning Representations* (ICLR).

## Medical Background and Clinical Context

10. **American Cancer Society** (2023). Cancer Facts & Figures 2023. Atlanta: American Cancer Society.

11. **Argenziano, G., Soyer, H. P., Chimenti, S., Talamini, R., Corona, R., Sera, F., ... & SIDS-EORTC.** (2003). Dermoscopy of pigmented skin lesions: Results of a consensus meeting via the Internet. *Journal of the American Academy of Dermatology*, 48(5), 679-693. DOI: 10.1067/mjd.2003.281

12. **Friedman, R. J., Rigel, D. S., & Kopf, A. W.** (1985). Early detection of malignant melanoma: The role of physician examination and self-examination of the skin. *CA: A Cancer Journal for Clinicians*, 35(3), 130-151.

## Explainable AI and Interpretability

13. **Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., & Torralba, A.** (2016). Learning deep features for discriminative localization. *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition* (CVPR), 2921-2929. DOI: 10.1109/CVPR.2016.319

14. **Sundararajan, M., Taly, A., & Yan, Q.** (2017). Axiomatic attribution for deep networks. *Proceedings of the 34th International Conference on Machine Learning* (ICML), 3319-3328.

15. **Rudin, C.** (2019). Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. *Nature Machine Intelligence*, 1(5), 206-215. DOI: 10.1038/s42256-019-0048-x

## Transfer Learning and Medical Imaging

16. **Deng, J., Dong, W., Socher, R., Li, L. J., Li, K., & Fei-Fei, L.** (2009). ImageNet: A large-scale hierarchical image database. *IEEE Conference on Computer Vision and Pattern Recognition* (CVPR), 248-255. DOI: 10.1109/CVPR.2009.5206848

17. **Raghu, M., Zhang, C., Kleinberg, J., & Bengio, S.** (2019). Transfusion: Understanding transfer learning for medical imaging. *Advances in Neural Information Processing Systems* (NeurIPS), 32, 3347-3357.

18. **Tajbakhsh, N., Shin, J. Y., Gurudu, S. R., Hurst, R. T., Kendall, C. B., Gotway, M. B., & Liang, J.** (2016). Convolutional neural networks for medical image analysis: Full training or fine tuning? *IEEE Transactions on Medical Imaging*, 35(5), 1299-1312. DOI: 10.1109/TMI.2016.2535302

## AI in Clinical Practice

19. **Topol, E. J.** (2019). High-performance medicine: The convergence of human and artificial intelligence. *Nature Medicine*, 25(1), 44-56. DOI: 10.1038/s41591-018-0300-7

20. **Yu, K. H., Beam, A. L., & Kohane, I. S.** (2018). Artificial intelligence in healthcare. *Nature Biomedical Engineering*, 2(10), 719-731. DOI: 10.1038/s41551-018-0305-z

21. **Obermeyer, Z., Powers, B., Vogeli, C., & Mullainathan, S.** (2019). Dissecting racial bias in an algorithm used to manage the health of populations. *Science*, 366(6464), 447-453. DOI: 10.1126/science.aax2342

## Software and Tools

22. **Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., ... & Chintala, S.** (2019). PyTorch: An imperative style, high-performance deep learning library. *Advances in Neural Information Processing Systems* (NeurIPS), 32, 8026-8037.

23. **Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., ... & Zheng, X.** (2016). TensorFlow: A system for large-scale machine learning. *12th USENIX Symposium on Operating Systems Design and Implementation* (OSDI), 265-283.

24. **Abid, A., Abdalla, A., Abid, A., Khan, D., Alfozan, A., & Zou, J.** (2019). Gradio: Hassle-free sharing and testing of ML models in the wild. *arXiv preprint arXiv:1906.02569*.

## Dataset and Benchmarks

25. **Codella, N. C., Gutman, D., Celebi, M. E., Helba, B., Marchetti, M. A., Dusza, S. W., ... & Halpern, A.** (2018). Skin lesion analysis toward melanoma detection: A challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), hosted by the International Skin Imaging Collaboration (ISIC). *IEEE 15th International Symposium on Biomedical Imaging* (ISBI), 168-172. DOI: 10.1109/ISBI.2018.8363547

26. **Combalia, M., Codella, N. C., Rotemberg, V., Helba, B., Vilaplana, V., Reiter, O., ... & Malvehy, J.** (2019). BCN20000: Dermoscopic lesions in the wild. *arXiv preprint arXiv:1908.02288*.

## Class Imbalance and Training Techniques

27. **Lin, T. Y., Goyal, P., Girshick, R., He, K., & Dollár, P.** (2017). Focal loss for dense object detection. *Proceedings of the IEEE International Conference on Computer Vision* (ICCV), 2980-2988. DOI: 10.1109/ICCV.2017.324

28. **Chawla, N. V., Bowyer, K. W., Hall, L. O., & Kegelmeyer, W. P.** (2002). SMOTE: Synthetic minority over-sampling technique. *Journal of Artificial Intelligence Research*, 16, 321-357. DOI: 10.1613/jair.953

## Uncertainty Quantification

29. **Gal, Y., & Ghahramani, Z.** (2016). Dropout as a Bayesian approximation: Representing model uncertainty in deep learning. *Proceedings of the 33rd International Conference on Machine Learning* (ICML), 1050-1059.

30. **Lakshminarayanan, B., Pritzel, A., & Blundell, C.** (2017). Simple and scalable predictive uncertainty estimation using deep ensembles. *Advances in Neural Information Processing Systems* (NeurIPS), 30, 6402-6413.

---

## Additional Reading

For readers seeking deeper understanding of specific topics, the following resources provide comprehensive coverage:

- **Medical AI Ethics**: Char, D. S., Shah, N. H., & Magnus, D. (2018). Implementing machine learning in health care—addressing ethical challenges. *New England Journal of Medicine*, 378(11), 981-983.

- **Dermoscopy Training**: Kittler, H., Pehamberger, H., Wolff, K., & Binder, M. (2002). Diagnostic accuracy of dermoscopy. *The Lancet Oncology*, 3(3), 159-165.

- **Deep Learning Theory**: Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.

- **Computer Vision**: Szeliski, R. (2022). *Computer Vision: Algorithms and Applications* (2nd ed.). Springer.

---

*Note: All URLs were accessed and verified as of November 2025. Digital Object Identifiers (DOIs) provide permanent links to publications and should be used for reliable access.*
